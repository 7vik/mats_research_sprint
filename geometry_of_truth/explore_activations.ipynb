{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./geometry-of-truth/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTS_BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './geometry-of-truth/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_acts(dataset_name, model_size, layer, center=True, scale=False, device='cpu'):\n",
    "    \"\"\"\n",
    "    Collects activations from a dataset of statements, returns as a tensor of shape [n_activations, activation_dimension].\n",
    "    \"\"\"\n",
    "    global ROOT, ACTS_BATCH_SIZE\n",
    "    directory = os.path.join(ROOT, 'acts', model_size, dataset_name)\n",
    "    activation_files = glob(os.path.join(directory, f'layer_{layer}_*.pt'))\n",
    "    acts = [t.load(os.path.join(directory, f'layer_{layer}_{i}.pt')).to(device) for i in range(0, ACTS_BATCH_SIZE * len(activation_files), ACTS_BATCH_SIZE)]\n",
    "    acts = t.cat(acts, dim=0).to(device)\n",
    "    if center:\n",
    "        acts = acts - t.mean(acts, dim=0)\n",
    "    if scale:\n",
    "        acts = acts / t.std(acts, dim=0)\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llama(device):\n",
    "    print(f'Loading Llama2')\n",
    "    llama_path = '/home/t-sgolechha/Desktop/llama2/llama/llama-2-7b_hf/'\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(llama_path)\n",
    "    model = LlamaForCausalLM.from_pretrained(llama_path)\n",
    "    # set tokenizer to use bos token\n",
    "    tokenizer.bos_token = '<s>'\n",
    "    model.to(device)\n",
    "    print(f'Loaded Llama2')\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Llama2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4efc7ff0854e40839b53f422f4c3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Llama2\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "tokenizer, model = load_llama(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMProbe(t.nn.Module):\n",
    "    def __init__(self, direction, covariance=None, inv=None, atol=1e-3):\n",
    "        super().__init__()\n",
    "        self.direction = t.nn.Parameter(direction, requires_grad=False)\n",
    "        if inv is None:\n",
    "            self.inv = t.nn.Parameter(t.linalg.pinv(covariance.cpu(), hermitian=True, atol=atol), requires_grad=False)\n",
    "            self.inv.to(device)\n",
    "        else:\n",
    "            self.inv = t.nn.Parameter(inv, requires_grad=False)\n",
    "\n",
    "    def forward(self, x, iid=False):\n",
    "        if iid:\n",
    "            return t.nn.Sigmoid()(x @ self.inv @ self.direction)\n",
    "        else:\n",
    "            return t.nn.Sigmoid()(x @ self.direction)\n",
    "\n",
    "    def pred(self, x, iid=False):\n",
    "        return self(x, iid=iid).round()\n",
    "\n",
    "    def from_data(acts, labels, atol=1e-3, device='cpu'):\n",
    "        acts, labels\n",
    "        pos_acts, neg_acts = acts[labels==1], acts[labels==0]\n",
    "        pos_mean, neg_mean = pos_acts.mean(0), neg_acts.mean(0)\n",
    "        direction = pos_mean - neg_mean\n",
    "\n",
    "        centered_data = t.cat([pos_acts - pos_mean, neg_acts - neg_mean], 0)\n",
    "        covariance = centered_data.t() @ centered_data / acts.shape[0]\n",
    "        \n",
    "        probe = MMProbe(direction, covariance=covariance).to(device)\n",
    "\n",
    "        return probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = range(model.config.num_hidden_layers)\n",
    "\n",
    "train_datasets = ['cities']\n",
    "val_dataset = 'sp_en_trans'\n",
    "\n",
    "ProbeClass = MMProbe\n",
    "\n",
    "# label tokens\n",
    "t_tok = tokenizer.encode('TRUE')[-1]\n",
    "f_tok = tokenizer.encode('FALSE')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:36<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "layer_directions = []\n",
    "\n",
    "for layer in tqdm(layers):\n",
    "    # get probe\n",
    "    if ProbeClass == LRProbe or ProbeClass == MMProbe:\n",
    "        acts, labels = [], []\n",
    "        for dataset in train_datasets:\n",
    "            acts.append(collect_acts(dataset, '7B', layer).to(device))\n",
    "            labels.append(t.Tensor(pd.read_csv(f'{ROOT}/datasets/{dataset}.csv')['label'].tolist()).to(device))\n",
    "        acts, labels = t.cat(acts), t.cat(labels)\n",
    "        probe = ProbeClass.from_data(acts, labels, device=device)\n",
    "    # get direction\n",
    "    direction = probe.direction\n",
    "    true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "    true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "    direction = direction / direction.norm()\n",
    "    diff = (true_mean - false_mean) @ direction\n",
    "    direction = diff * direction\n",
    "\n",
    "    layer_directions.append(direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_directions_t = t.stack(layer_directions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4096])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_directions_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_directions_t_path = '/home/t-sgolechha/Desktop/mats_research_sprint/directions/llama2_7b_mm_layer_directions_cities.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(layer_directions_t, layer_directions_t_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probe\n",
    "if ProbeClass == LRProbe or ProbeClass == MMProbe:\n",
    "    acts, labels = [], []\n",
    "    for dataset in train_datasets:\n",
    "        acts.append(collect_acts(dataset, '7B', layer).to(device))\n",
    "        labels.append(t.Tensor(pd.read_csv(f'{ROOT}/datasets/{dataset}.csv')['label'].tolist()).to(device))\n",
    "    acts, labels = t.cat(acts), t.cat(labels)\n",
    "    probe = ProbeClass.from_data(acts, labels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get direction\n",
    "direction = probe.direction\n",
    "true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "direction = direction / direction.norm()\n",
    "diff = (true_mean - false_mean) @ direction\n",
    "direction = diff * direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "The Spanish word 'jirafa' means 'giraffe'. This statement is: TRUE\n",
    "The Spanish word 'escribir' means 'to write'. This statement is: TRUE\n",
    "The Spanish word 'diccionario' means 'dictionary'. This statement is: TRUE\n",
    "The Spanish word 'gato' means 'cat'. This statement is: TRUE\n",
    "The Spanish word 'aire' means 'silver'. This statement is: FALSE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure everything is clean going in\n",
    "for module in model.model.layers:\n",
    "    module._forward_hooks.clear()\n",
    "\n",
    "df_out = {'alpha' : [], 'diff' : [], 'tot' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep increasing alpha until things get worse\n",
    "last_diff = -2\n",
    "diff = -1\n",
    "tot = 1\n",
    "alpha = -1\n",
    "while diff > last_diff and tot > .95:\n",
    "    last_diff = diff\n",
    "    alpha += 1\n",
    "    # get probs\n",
    "    df = pd.read_csv(f'datasets/{val_dataset}.csv')\n",
    "    diffs, tots = [], []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        if row['label'] == 0 and row['statement'] not in prompt:\n",
    "            input_ids = tokenizer(prompt + '\\n' +  row['statement'] + ' This statement is:', return_tensors='pt').input_ids.to(device)\n",
    "            period_tok = tokenizer.encode(\"'test'.\")[-1]\n",
    "            period_idxs = (input_ids == period_tok).nonzero(as_tuple=True)[1]\n",
    "            intervention_idx = period_idxs[5]\n",
    "\n",
    "            # intervened prob\n",
    "            def hook(module, input, output):\n",
    "                output[0][:,intervention_idx - 1, :] += direction * alpha\n",
    "                output[0][:, intervention_idx, :] += direction * alpha\n",
    "                return output\n",
    "            handle = model.model.layers[layer-1].register_forward_hook(hook)\n",
    "            probs = model(input_ids).logits[0,-1,:].softmax(-1)\n",
    "            handle.remove()\n",
    "\n",
    "            diffs.append(probs[t_tok].item() - probs[f_tok].item())\n",
    "            tots.append(probs[t_tok].item() + probs[f_tok].item())\n",
    "    diff = sum(diffs) / len(diffs)\n",
    "    tot = sum(tots) / len(tots)\n",
    "    df_out['alpha'].append(alpha)\n",
    "    df_out['diff'].append(diff)\n",
    "    df_out['tot'].append(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "log = {\n",
    "    'train_datasets' : train_datasets,\n",
    "    'val_dataset' : val_dataset,\n",
    "    'layer' : layer,\n",
    "    'probe class' : ProbeClass.__name__,\n",
    "    'prompt' : prompt,\n",
    "    'results' : df_out,\n",
    "    'experiment' : 'false to true'\n",
    "}\n",
    "\n",
    "with open('experimental_outputs/label_change_intervention_results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data.append(log)\n",
    "with open('experimental_outputs/label_change_intervention_results.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(pd.DataFrame(df_out), x='alpha', y=['diff', 'tot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1496, 4096])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcs(X, k=2, offset=0):\n",
    "    \"\"\"\n",
    "    Performs Principal Component Analysis (PCA) on the n x d data matrix X. \n",
    "    Returns the k principal components, the corresponding eigenvalues and the projected data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Subtract the mean to center the data\n",
    "    X = X - t.mean(X, dim=0)\n",
    "    \n",
    "    # Compute the covariance matrix\n",
    "    cov_mat = t.mm(X.t(), X) / (X.size(0) - 1)\n",
    "    \n",
    "    # Perform eigen decomposition\n",
    "    eigenvalues, eigenvectors = t.linalg.eigh(cov_mat.cpu())\n",
    "    eigenvalues = eigenvalues.to(device)\n",
    "    eigenvectors = eigenvectors.to(device)\n",
    "    \n",
    "    # Since the eigenvalues and vectors are not necessarily sorted, we do that now\n",
    "    sorted_indices = t.argsort(eigenvalues, descending=True)\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Select the pcs\n",
    "    eigenvectors = eigenvectors[:, offset:offset+k]\n",
    "    \n",
    "    return eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = get_pcs(acts, k=2, offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "pcs_layer = []\n",
    "# compute pcs for each layer\n",
    "for layer in tqdm(layers):\n",
    "    acts = collect_acts('cities', '7B', layer).to(device)\n",
    "    pcs = get_pcs(acts, k=2, offset=0)\n",
    "    pcs_layer.append(pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 27.30it/s]\n"
     ]
    }
   ],
   "source": [
    "proj_layer = []\n",
    "# project each layer activations to pcs\n",
    "for layer in tqdm(layers):\n",
    "    acts = collect_acts('cities', '7B', layer).to(device)\n",
    "    proj = acts @ pcs_layer[layer]\n",
    "    proj_layer.append(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_layer_t = t.stack(proj_layer, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1496, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_layer_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ntensor_to_long(proj_layer_t, dim_names=['layer', 'datapoint', 'pc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pc1\"] = proj_layer_t[:, :, 0].flatten().cpu().numpy()\n",
    "df[\"pc2\"] = proj_layer_t[:, :, 1].flatten().cpu().numpy()\n",
    "df[\"layer\"] = np.repeat(np.arange(32), 1496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47872, 3), Index(['pc1', 'pc2', 'layer'], dtype='object'))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = t.Tensor(pd.read_csv(f'{ROOT}/datasets/{dataset}.csv')['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = np.tile(labels.cpu().numpy(), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1,\n",
       "       2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3,\n",
       "       4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,\n",
       "       1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2,\n",
       "       3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4,\n",
       "       0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1,\n",
       "       2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3,\n",
       "       4, 0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.arange(5), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x=\"pc1\", y=\"pc2\", animation_frame=\"layer\", color=\"label\", height=600, width=600)\n",
    "fig.write_html(\"pc2_llama2-7b-cities.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1496, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_layer_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4096])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_directions_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
